{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running out of disk memory run <br>\n",
    "`cd /tmp/`<br>\n",
    "`rm -r *`\n",
    "https://stackoverflow.com/questions/47802148/decodeerror-error-parsing-message-on-evaluation-of-tensorflow-object-detection <br>\n",
    "`export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python`\n",
    "https://github.com/tensorflow/tensorflow/issues/36885\n",
    "https://github.com/tensorflow/tensorflow/issues/582\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither PyTorch nor TensorFlow >= 2.0 have been found.Models won't be available and only tokenizers, configurationand file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "import tensorflow_datasets as tfds\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "from bert import run_classifier_with_tfhub\n",
    "#https://github.com/google-research/bert.git\n",
    "import sys\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import re\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import pickle\n",
    "import gc\n",
    "import threading\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All devices:  8\n"
     ]
    }
   ],
   "source": [
    "# Based on -> https://towardsdatascience.com/https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca\n",
    "# Active TPU'1\n",
    "TPU_ADDRESS = \"node-2\"\n",
    "TPU_ZONE = \"us-central1-f\"\n",
    "USE_TPU =True\n",
    "NUM_TPU_CORES = 8\n",
    "#len(tf.config.experimental.list_logical_devices('TPU'))\n",
    "\n",
    "#tf.config.experimental_connect_to_cluster(resolver)\n",
    "#tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "#tpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "#print(\"All devices: \", tf.config.experimental.list_logical_devices('TPU'))\n",
    "\n",
    "# Setup TPU related config\n",
    "#tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
    "#NUM_TPU_CORES = 8\n",
    "\n",
    "#https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb#scrollTo=191zq3ZErihP\n",
    "#with tf.Session(TPU_ADDRESS) as session:\n",
    "   # print('TPU devices:')\n",
    "   # pprint.pprint(session.list_devices())    \n",
    "    #contrib.cloud.configure_gcs(session)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDir(bucket, output_dir):\n",
    "    return 'gs://{}/{}'.format(bucket, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: gs://patents-research/bertResults *****\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"bertResults_192_17upweight\"\n",
    "DO_DELETE = True\n",
    "USE_BUCKET =True\n",
    "BUCKET = \"patents-research\"\n",
    "\n",
    "if USE_BUCKET:\n",
    "    OUTPUT_DIR = getDir(BUCKET, OUTPUT_DIR)\n",
    "\n",
    "\n",
    "if DO_DELETE:\n",
    "    try:\n",
    "        tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "    except:\n",
    "        # doesn't matter if the directory didn't exist\n",
    "        pass\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Set\n",
    "\n",
    "We classify high impact patents following (Ahuja and Lampert, 2001) as the patents\n",
    " within a given cohort receiving the most citations by other patents within the following 5 year window. Thereafter, for every year we sorted\n",
    "the patents applied for in that year on the basis\n",
    "of their citation weights and identified the top 1\n",
    "percent of patents for that year as breakthrough\n",
    "inventions. This procedure ensures that each patent is compared in its importance only to other\n",
    "patents of the same yea\n",
    "https://towardsdatascience.com/https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPdData(gsPath):\n",
    "    return pd.read_csv(gsPath, sep = \"\\t\")\n",
    "\n",
    "def saveToGcloud(path,data,isPandas = False ):\n",
    "    '''Saves to gcloud so we dont have to do this long ass step every time'''\n",
    "    if isPandas:\n",
    "        data.to_csv(path, index=False, sep=\"\\t\")\n",
    "    else:\n",
    "        with file_io.FileIO(path, mode='w') as f:\n",
    "            pickle.dump(data,f)\n",
    "\n",
    "\n",
    "def readFromGcloud(path, isPandas = False):\n",
    "    if isPandas:\n",
    "        return pd.read_csv(path,sep=\"\\t\" )\n",
    "    else:\n",
    "        with file_io.FileIO(path, mode='rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the data\n",
    "DATA_PATH = \"gs://patents-research/patent_research/data_frwdcorrect.tsv\"\n",
    "TRAIN_DF_PATH= \"gs://patents-research/patent_research/{}\".format(\"bert_train_df.tsv\") \n",
    "TEST_DF_PATH=\"gs://patents-research/patent_research/{}\".format(\"bert_test_df.tsv\")\n",
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1, 2] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing + Loading Training \n",
    "**(We load Test asyncronously later)**\n",
    "\n",
    "Converting data into format that bert understands. We use https://github.com/allenai/scibert instead of the standard tokenizer/trained model ref= https://www.aclweb.org/anthology/D19-1371.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HUB_MODULE = \"https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/tensorflow_models/scibert_scivocab_uncased.tar.gz\"\n",
    "TRAIN_TFRecord_PATH= \"gs://patents-research/patent_research/train_features_192.pickle\"\n",
    "TEST_TFRecord_PATH= \"gs://patents-research/patent_research/test_features_192.pickle\"\n",
    "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1'\n",
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 192 #default sequence is 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get around memory and increase seq length? : https://tfhub.dev/tensorflow/albert_lite_base/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved data from cloud!\n",
      "Finished loading saved data from cloud!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_features= readFromGcloud(TRAIN_TFRecord_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download test data \n",
    "\n",
    "Threading this so we can train immediately, and we are not stuck waiting on test data to download when we don't need it immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_downloadTestData(name):\n",
    "    \"\"\"\n",
    "    Worker so we can download test data asynch\n",
    "    \"\"\"\n",
    "    logging.info(\"Thread %s: starting\", name)\n",
    "    global test_features\n",
    "    test_features = readFromGcloud(TEST_TFRecord_PATH)\n",
    "    logging.info(\"Thread %s: finishing\", name)   \n",
    "\n",
    "def worker_downloadTrainData(name):\n",
    "    \"\"\"\n",
    "    Worker so we can download test data asynch\n",
    "    \"\"\"\n",
    "    logging.info(\"Thread %s: starting\", name)\n",
    "    global train_features\n",
    "    train_features = readFromGcloud(TRAIN_TFRecord_PATH)\n",
    "    logging.info(\"Thread %s: finishing\", name)   \n",
    "\n",
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.INFO,datefmt=\"%H:%M:%S\")\n",
    "getTestData_thread = threading.Thread(target=worker_downloadTestData, args=(1,))\n",
    "getTestData_thread.start() #async download of test data\n",
    "\n",
    "#logging.basicConfig(format=format, level=logging.INFO,datefmt=\"%H:%M:%S\")\n",
    "#getTrainData_thread = threading.Thread(target=worker_downloadTrainData, args=(2,))\n",
    "#getTrainData_thread.start() #async download of test data \n",
    "\n",
    "#labels = tf.constant([2,0,1])\n",
    "#per_example_loss = tf.constant([.1,.1,.1])\n",
    "\n",
    "\n",
    "#wieghts = tf.constant([[1,1,1,1],[1,1,1,1], [1,1,1,1]] )\n",
    "\n",
    "\n",
    "#mask = tf.logical_or(tf.equal(labels, 1), tf.equal(labels, 2))\n",
    "#lossy = tf.where(mask, per_example_loss*5,per_example_loss)\n",
    "\n",
    "\n",
    "#sess.run(tf.matmul(diag, wieghts, transpose_b=False))\n",
    "\n",
    "\n",
    "#sess.run(tf.ones_like(labels))\n",
    "\n",
    "#predictions = tf.constant([2,0,1,1,2,1,1,0])\n",
    "\n",
    "#sess = tf.compat.v1.Session()\n",
    "#var1 = tf.Variable(3.,dtype=tf.float64)\n",
    "#var2 = tf.get_variable(\"var1\",[],dtype=tf.float64)\n",
    "\n",
    "#tf.equal(c, 1)\n",
    "#tf.equal(c, 2)\n",
    "\n",
    "#for\n",
    "\n",
    "#sess.run(tf.ones_like(labels)*5)\n",
    "\n",
    "#sess.run(tf.constant(2, shape = tf.shape(labels)))\n",
    "\n",
    "\n",
    "#sess.run(getClassTotalPredicted(0,1,labels,predictions))\n",
    "#sess.run(getClassTotalPredicted(2, labels, predictions, classes = [0,1,2]))\n",
    "\n",
    "#two = tf.constant(2)\n",
    "#where = tf.equal(c, two)\n",
    "#get_sum = tf.dtypes.cast(where, tf.int32)\n",
    "#sess.run(where)\n",
    "#sess.run(getClassTotal(2,labels))\n",
    "#labels_subset = tf.where(tf.equal(labels, tf.constant(1)), tf.zeros_like(labels), labels)\n",
    "\n",
    "#sess.run(labels_subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering fixing imbalance based on: https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampleData(train_features_1, proportion_of_minority_class = .20):\n",
    "    \"\"\"\n",
    "    Downsamples the negative such that the positive classes make up `proportion_of_minority_class`\n",
    "    percent of total examples\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "        \"upweightFactor\":  The factor downsampling majorty class by\n",
    "        \"proportion_of_positives\": The actual proprotion we are able to achiieve\n",
    "        \"num_negative\": The number of negative examples left in dataset\n",
    "        \"num_positive\": The number of positive examples in dataset\n",
    "        }\n",
    "    \"\"\"\n",
    "    random.shuffle(train_features_1)\n",
    "    \n",
    "    # Find the indices of negative example and count the number of \n",
    "    positive_example_count = 0\n",
    "    negative_example_idx = []\n",
    "    for i,example in enumerate(train_features_1):\n",
    "        if example.label_id == 0:\n",
    "            negative_example_idx.append(i)\n",
    "        else:\n",
    "            positive_example_count+=1\n",
    "    \n",
    "\n",
    "    i = 1\n",
    "    threshold = 0\n",
    "    while threshold<proportion_of_minority_class:\n",
    "        \n",
    "        threshold = positive_example_count/(positive_example_count+len(train_features_1)//i)\n",
    "        i+=1\n",
    "        \n",
    "    # undersample the dataset\n",
    "    target_neg_examples = len(train_features_1)//i\n",
    "    while len(negative_example_idx)>target_neg_examples:\n",
    "        idx= negative_example_idx.pop()\n",
    "        train_features_1.pop(idx)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"upweightFactor\":i, \n",
    "        \"proportion_of_positives\": threshold, \n",
    "        \"num_negative\": len(negative_example_idx),\n",
    "        \"num_positive\": positive_example_count\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_training, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels, bert_hub_module_handle, dropout, upweight=False):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "    tags = set()\n",
    "    if is_training:\n",
    "        tags.add(\"train\")\n",
    "    bert_module = hub.Module(bert_hub_module_handle, tags=tags, trainable=True)\n",
    "    bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        if is_training:\n",
    "            # I.e., 0.1 dropout\n",
    "            output_layer = tf.nn.dropout(output_layer, keep_prob=dropout)\n",
    "\n",
    "\n",
    "        #Multiplies matrix a by matrix b, producing a * b.\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        \n",
    "        # upweighting the loss\n",
    "        if is_training and upweight:\n",
    "            mask = tf.logical_or(tf.equal(labels, 1), tf.equal(labels, 2))\n",
    "            per_example_loss = tf.where(mask, per_example_loss*upweight,per_example_loss)\n",
    "\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "\n",
    "        return (loss, per_example_loss, logits, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps, use_tpu, bert_hub_module_handle, dropout, upweight = False):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "\n",
    "    def model_fn(features, labels, mode, params):  \n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        tf.logging.info(\"*** Features ***\")\n",
    "        for name in sorted(features.keys()):\n",
    "            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "        (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
    "                is_training, input_ids, input_mask, segment_ids, label_ids, num_labels,\n",
    "                bert_hub_module_handle, dropout, upweight)\n",
    "\n",
    "        output_spec = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = optimization.create_optimizer(\n",
    "                    total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
    "\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  loss=total_loss,\n",
    "                  train_op=train_op)\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            \n",
    "            \n",
    "            def metric_fn(per_example_loss, label_ids, logits):\n",
    "                               \n",
    "                \n",
    "                predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predictions)\n",
    "                loss = tf.metrics.mean(per_example_loss)\n",
    "                true_pos = tf.metrics.true_positives(\n",
    "                            label_ids,\n",
    "                            predictions)\n",
    "                true_neg = tf.metrics.true_negatives(\n",
    "                            label_ids,\n",
    "                            predictions)   \n",
    "                false_pos = tf.metrics.false_positives(\n",
    "                            label_ids,\n",
    "                            predictions)  \n",
    "                false_neg = tf.metrics.false_negatives(\n",
    "                            label_ids,\n",
    "                            predictions) \n",
    "                \n",
    "                \n",
    "                # Turn into 0-1 on the 95% labels and output statistics. \n",
    "                where  = tf.equal(label_ids, tf.constant(2))\n",
    "                mask =tf.where(where)\n",
    "                predictions_subset = tf.gather_nd(predictions,mask)\n",
    "                label_subset = tf.gather_nd(label_ids,mask)\n",
    "                # replace the other class prediction w/ zero so it turns up as negative\n",
    "                predictions_subset = tf.where(tf.equal(predictions_subset, tf.constant(1)), tf.zeros_like(predictions_subset), predictions_subset)\n",
    "\n",
    "            \n",
    "                accuracy_95 = tf.metrics.accuracy(label_subset, predictions_subset)\n",
    "                true_pos_95 = tf.metrics.true_positives(\n",
    "                            label_subset,\n",
    "                            predictions_subset)\n",
    "  \n",
    "                false_neg_95 = tf.metrics.false_negatives(\n",
    "                            label_subset,\n",
    "                            predictions_subset) \n",
    "                \n",
    "                # Turn into 0-1 on the 99% labels and output statistics. \n",
    "                where  = tf.equal(label_ids, tf.constant(1))\n",
    "                mask =tf.where(where)\n",
    "                predictions_subset = tf.gather_nd(predictions,mask)\n",
    "                label_subset = tf.gather_nd(label_ids,mask)\n",
    "                predictions_subset = tf.where(tf.equal(predictions_subset, tf.constant(2)), tf.zeros_like(predictions_subset), predictions_subset)\n",
    "\n",
    "                accuracy_99 = tf.metrics.accuracy(label_subset, predictions_subset)\n",
    "\n",
    "                true_pos_99 = tf.metrics.true_positives(\n",
    "                            label_subset,\n",
    "                            predictions_subset)\n",
    "\n",
    "\n",
    "                false_neg_99 = tf.metrics.false_negatives(\n",
    "                            label_subset,\n",
    "                            predictions_subset) \n",
    "\n",
    "                \n",
    "                return {\n",
    "                    \"accuracy_99\":accuracy_99,\n",
    "                    \"true_pos_99\":true_pos_99,\n",
    "                    \"false_neg_99\":false_neg_99,\n",
    "                    \"accuracy_95\":accuracy_95,\n",
    "                    \"true_pos_95\":true_pos_95,\n",
    "                    \"false_neg_95\":false_neg_95,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg,\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"eval_loss\": loss,\n",
    "                }\n",
    "\n",
    "            eval_metrics = (metric_fn, [per_example_loss, label_ids, logits])\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "              mode=mode,\n",
    "              loss=total_loss,\n",
    "              eval_metrics=eval_metrics)\n",
    "        \n",
    "        elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "              mode=mode, predictions={\"probabilities\": probabilities})\n",
    "        else:\n",
    "            raise ValueError(\n",
    "              \"Only TRAIN, EVAL and PREDICT modes are supported: %s\" % (mode))\n",
    "\n",
    "        return output_spec\n",
    "\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL PARAMETERS\n",
    "\n",
    "Example params\n",
    "- https://github.com/google-research/bert/issues/649 \n",
    "- https://github.com/google-research/bert/issues/425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 64\n",
    "EVAL_BATCH_SIZE = NUM_TPU_CORES\n",
    "PREDICT_BATCH_SIZE = NUM_TPU_CORES\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 40.0\n",
    "DROPOUT_KEEP_PROB = .7\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 1000\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "#DOWN_SAMPLE_STATS = downsampleData(train_features, proportion_of_minority_class = .50)\n",
    "#DOWN_SAMPLE_FACTOR = DOWN_SAMPLE_STATS[\"upweightFactor\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int((len(train_features)) / BATCH_SIZE * NUM_TRAIN_EPOCHS) \n",
    "#int((800000) / 256 * 40) == about 32k - 218000\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up TPU \n",
    "https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb#scrollTo=pYVYULZiKvUi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: node-2\n",
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Querying Tensorflow master (grpc://10.157.197.34:8470) for TPU system metadata.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3455271994140814130)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10245224255260713639)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16321600984248760639)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17663426012522639575)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11435110670809846027)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6307267863733612813)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3355277580655669410)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13181272993684034916)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15590471316025377131)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6836388459525237273)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6802283676312934250)\n"
     ]
    }
   ],
   "source": [
    "# Setupt TPU related config\n",
    "tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_ADDRESS, zone=TPU_ZONE)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)\n",
    "tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)\n",
    "\n",
    "ITERATIONS_PER_LOOP = 1000\n",
    "\n",
    "# Force TF Hub writes to the GS bucket we provide.\n",
    "os.environ['TFHUB_CACHE_DIR'] =  os.path.join(OUTPUT_DIR,\"tfhub_cache\")\n",
    "tf.gfile.MakeDirs(os.path.join(OUTPUT_DIR,\"tfhub_cache\"))\n",
    "\n",
    "#490132\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Train + Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_config(output_dir):\n",
    "    \"\"\"\n",
    "    Used for run configuration when TPU used\n",
    "    \"\"\"\n",
    "    return tf.contrib.tpu.RunConfig(\n",
    "        cluster=tpu_cluster_resolver,\n",
    "        model_dir=output_dir,\n",
    "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "        tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "            iterations_per_loop=ITERATIONS_PER_LOOP,\n",
    "            num_shards=NUM_TPU_CORES,\n",
    "            per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
    "\n",
    "def getEstimator(mode_fn):\n",
    "    \"\"\"\n",
    "    Returns the estimator used to train/eval model\n",
    "    \"\"\"\n",
    "    return tf.estimator.tpu.TPUEstimator(\n",
    "          use_tpu=True,\n",
    "          model_fn=mode_fn,\n",
    "          config=get_run_config(OUTPUT_DIR),\n",
    "          train_batch_size=BATCH_SIZE,\n",
    "          eval_batch_size=EVAL_BATCH_SIZE,\n",
    "          predict_batch_size=PREDICT_BATCH_SIZE,\n",
    "          eval_on_tpu = True\n",
    "        ) \n",
    "\n",
    "def model_train(estimator):\n",
    "    \"\"\"\n",
    "    Trains the model, rt only good for TPU\n",
    "    \"\"\"\n",
    "    #Set drop_remainder =True to fix a TPU error\n",
    "    #https://stackoverflow.com/questions/58029896/bert-fine-tuning-with-estimators-on-tpus-on-colab-typeerror-unsupported-operand\n",
    "\n",
    "    print('***** Started training at {} *****'.format(datetime.now()))\n",
    "    print('  Num examples = {}'.format(len(train_features)))\n",
    "    print('  Batch size = {}'.format(BATCH_SIZE))\n",
    "    tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    train_input_fn = run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=True)\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "    print(\"Finished: Training took time \", datetime.now() - current_time)\n",
    "\n",
    "    #train_features\n",
    "def model_evaluate(estimator, data, fname=\"\"):\n",
    "    \"\"\"\n",
    "    Evaluates the model\n",
    "    \"\"\"\n",
    "    print('***** Started evaluation at {} *****'.format(datetime.now()))\n",
    "    print('  Num examples = {}'.format(len(data)))\n",
    "    print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
    "\n",
    "    # Eval will be slightly WRONG on the TPU because it will truncate\n",
    "    # the last batch.\n",
    "    eval_steps = int(len(data) / EVAL_BATCH_SIZE)\n",
    "    \n",
    "    eval_input_fn = run_classifier.input_fn_builder(\n",
    "        features=data,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=True)\n",
    "    \n",
    "    result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
    "    print('***** Finished evaluation at {} *****'.format(datetime.now()))\n",
    "    output_eval_file = os.path.join(OUTPUT_DIR, \"eval\",\"eval_results{}.txt\".format(fname))\n",
    "    #tf.gfile.MakeDirs(os.path.join(OUTPUT_DIR, \"eval\"))\n",
    "    with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
    "        print(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            print('  {} = {}'.format(key, str(result[key])))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train + Eval model\n",
    "If evaluate breaks down must rm the lock file in `TFHUB_CACHE_DIR` unless stuck waiting -> https://github.com/tensorflow/hub/issues/579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps,\n",
    "  dropout = DROPOUT_KEEP_PROB,\n",
    "  use_tpu = USE_TPU,\n",
    "  bert_hub_module_handle = BERT_MODEL_HUB,\n",
    "    upweight = 17\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = getEstimator(mode_fn) \n",
    "model_train(estimator)\n",
    "getTestData_thread.join()\n",
    "model_evaluate(estimator, test_features, fname=\"nane_goes_here\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patent-modeling",
   "language": "python",
   "name": "patent-modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
