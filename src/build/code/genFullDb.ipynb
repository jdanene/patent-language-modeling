{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query that merges cleaned_claims with all the other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from google.cloud import storage\n",
    "import os\n",
    "import pandas as pd \n",
    "from google.cloud import bigquery\n",
    "import sys \n",
    "\n",
    "#%load_ext google.colab.data_tableÃ¥\n",
    "\n",
    "# authenticate self\n",
    "#from google.colab import auth\n",
    "#auth.authenticate_user()\n",
    "#print('Authenticated')\n",
    "\n",
    "\n",
    "\n",
    "QUERY=\"\"\"\n",
    "SELECT app.patent_id as patent_id, app.date as publication_date, filterData.bkwdCitations, filterData.fwrdCitations_5, patent.title, patent.abstract, claims\n",
    "FROM\n",
    "  (SELECT claims, CAST(patent_id AS STRING) as patent_id\n",
    "   FROM `patents-research-275923.patents.cleaned_claims`) as claims,\n",
    "  `patents-public-data.patentsview.patent` as patent,\n",
    "  `patents-public-data.patentsview.application` as app,\n",
    "  (SELECT DISTINCT cpc.patent_id, IFNULL(citation_5.bkwdCitations, 0) as bkwdCitations, IFNULL(citation_5.fwrdCitations_5, 0) as fwrdCitations_5\n",
    "  FROM\n",
    "    `patents-public-data.patentsview.cpc_current` AS cpc\n",
    "    LEFT JOIN\n",
    "    (SELECT  b.patent_id, b.bkwdCitations, f.fwrdCitations_5\n",
    "      FROM \n",
    "\n",
    "        (SELECT \n",
    "          cited.citation_id as patent_id,\n",
    "          IFNULL(COUNT(*),0) as fwrdCitations_5\n",
    "          FROM \n",
    "          `patents-public-data.patentsview.uspatentcitation` AS cited,\n",
    "          `patents-public-data.patentsview.application` AS apps\n",
    "        WHERE\n",
    "          apps.country = 'US'\n",
    "          AND cited.citation_id = apps.patent_id \n",
    "          AND cited.date >= apps.date AND SAFE_CAST(cited.date AS DATE) <= DATE_ADD(SAFE_CAST(apps.date AS DATE), INTERVAL 5 YEAR) -- get in 5year interval \n",
    "         GROUP BY \n",
    "         cited.citation_id) AS f,\n",
    "\n",
    "       (SELECT \n",
    "          cited.patent_id,\n",
    "          IFNULL(COUNT(*),0) as bkwdCitations\n",
    "          FROM \n",
    "          `patents-public-data.patentsview.uspatentcitation` AS cited,\n",
    "          `patents-public-data.patentsview.application` AS apps\n",
    "        WHERE\n",
    "          apps.country = 'US'\n",
    "          AND cited.patent_id = apps.patent_id \n",
    "          AND cited.date < apps.date -- get all backward citatoin count\n",
    "         GROUP BY \n",
    "         cited.patent_id) AS b\n",
    "      WHERE\n",
    "      b.patent_id = f.patent_id AND b.bkwdCitations IS NOT NULL AND f.fwrdCitations_5 IS NOT NULL) AS citation_5 \n",
    "      ON cpc.patent_id=citation_5.patent_id\n",
    "      WHERE\n",
    "       (cpc.subsection_id IN ('C05', 'C07', 'C08', 'C09', 'C11', 'C12', 'C13', 'C25', 'C40')\n",
    "        OR cpc.group_id in ('A01G', 'A01H', 'A61K', 'A61P', 'A61Q', 'B01F', 'B01J', 'B81B', 'B82B', 'B82Y','G01N', 'G16H')))\n",
    "  as filterData\n",
    "  WHERE\n",
    "  app.patent_id = filterData.patent_id AND app.patent_id = patent.id \n",
    "  AND SAFE_CAST(app.date AS DATE) < '2014-01-01' AND claims.patent_id  =app.patent_id\n",
    "\"\"\"\n",
    "\n",
    "QUERY2 = \"\"\"\n",
    "SELECT db.patent_id, db.fwrdCitations_5, db.abstract , db.claims , db.title , db.publication_date , IFNULL(backcited.backcited, \"<start -backcitedcount>0<end -backcitedcount>\")  as bkwdCitations \n",
    "FROM (SELECT app.patent_id as patent_id, app.date as publication_date,filterData.fwrdCitations_5, patent.title, patent.abstract, claims\n",
    "FROM\n",
    "  \n",
    "  (SELECT claims, CAST(patent_id AS STRING) as patent_id\n",
    "   FROM `patents-research-275923.patents.cleaned_claims`) as claims,\n",
    "  `patents-public-data.patentsview.patent` as patent,\n",
    "  `patents-public-data.patentsview.application` as app,\n",
    "  (SELECT DISTINCT cpc.patent_id, IFNULL(citation_5.fwrdCitations_5, 0) as fwrdCitations_5\n",
    "  FROM\n",
    "    `patents-public-data.patentsview.cpc_current` AS cpc\n",
    "    LEFT JOIN\n",
    "        \n",
    "        -- This query gets the forward citation count\n",
    "        (SELECT \n",
    "          cited.citation_id as patent_id, IFNULL(COUNT(*),0) as fwrdCitations_5\n",
    "          FROM \n",
    "           `patents-public-data.patentsview.patent` AS patent,\n",
    "          `patents-public-data.patentsview.uspatentcitation` AS cited,\n",
    "          `patents-public-data.patentsview.application` AS application\n",
    "          WHERE\n",
    "            patent.id = cited.patent_id AND cited.citation_id = application.patent_id\n",
    "            AND (patent.date >= application.date AND SAFE_CAST(patent.date AS DATE) <= DATE_ADD(SAFE_CAST(application.date AS DATE), INTERVAL 5 YEAR))\n",
    "          GROUP BY\n",
    "            cited.citation_id) AS citation_5\n",
    "         \n",
    "      ON cpc.patent_id=citation_5.patent_id\n",
    "      WHERE\n",
    "       (cpc.subsection_id IN ('C05', 'C07', 'C08', 'C09', 'C11', 'C12', 'C13', 'C25', 'C40')\n",
    "        OR cpc.group_id in ('A01G', 'A01H', 'A61K', 'A61P', 'A61Q', 'B01F', 'B01J', 'B81B', 'B82B', 'B82Y','G01N', 'G16H')))\n",
    "  as filterData\n",
    "  WHERE\n",
    "  app.patent_id = filterData.patent_id AND app.patent_id = patent.id \n",
    "  AND SAFE_CAST(app.date AS DATE) < '2014-01-01' AND claims.patent_id  =app.patent_id) as db\n",
    "  LEFT JOIN `patents-research-275923.patents.backcited` as backcited ON CAST(backcited.patent_id AS STRING) = db.patent_id\n",
    "\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "PROJECT_ID = \"patents-research-275923\"\n",
    "CLOUD_BUCKET_NAME = \"patents-research\"\n",
    "CLOUD_FILEPATH = \"patent_research/data.tsv\"\n",
    "\n",
    "COLUMNS = ['patent_id', 'fwrdCitations_5','publication_date','bkwdCitations','title', 'abstract', 'claims']\n",
    "START_TOKENS = ['<start -id>','<start -date>', '<start -backcited>', '<start -title>',  '<start -abstract>', '<start -claims>']\n",
    "END_TOKENS = ['<end -id>','<end -date>', '<end -backcited>','<end -title>',  '<end -abstract>','<end -claims>' ]\n",
    "VAR_COLUMNS = ['patent_id','publication_date','bkwdCitations', 'title', 'abstract', 'claims']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Functions to push to google storage and concatenate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ctrl-\n",
    "def addFieldTokens(df, start_tokens, end_tokens, col_names):\n",
    "    '''\n",
    "    Iterate through all df columns; \n",
    "    append the start tokens as a prefix to the data;\n",
    "    append the end tokens as a suffix to the data;\n",
    "    '''\n",
    "    for i, col in enumerate(col_names):  # iter thru the \"variable\" columns (3:end)\n",
    "            # set rows to be of format: start token, data, end token\n",
    "            if col != 'claims' and col!='bkwdCitations':\n",
    "                df[col_names[i]] = df[col_names[i]].apply(lambda x: start_tokens[i]+str(x)+ end_tokens[i])\n",
    "                    \n",
    "                #df[col_names[i]] = start_tokens[i] + df[col_names[i]].astype(str) + end_tokens[i]\n",
    "    return df\n",
    "\n",
    "def concatColumns(df):\n",
    "    '''\n",
    "    Function to condense preprocessed and field tokenized columns into one column\n",
    "    This column contains a single concatenated string with all metadata\n",
    "    '''\n",
    "    #\tid\tlabel\talpha\ttext\n",
    "    #df[\"text\"] = df[\"publication_date\"]+df[\"bkwdCitations\"]+df[\"title\"]+df[\"summary_text\"]+df[\"claims\"]\n",
    "    df[\"text\"] = \"\"\n",
    "    i=0\n",
    "    for col in VAR_COLUMNS:\n",
    "        df[\"text\"]+= df[col]\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "        i+=1\n",
    "        print(\"{}/{} done\".format(i,len(VAR_COLUMNS)))\n",
    "\n",
    "def upload_df_toGoogle(data_frame, filepath=\"patent_research/data2.tsv\"):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "    \n",
    "    # create bucket if it does not exists\n",
    "    STORAGE_CLIENT = storage.Client()\n",
    "    if not STORAGE_CLIENT.lookup_bucket(CLOUD_BUCKET_NAME):\n",
    "        STORAGE_CLIENT.create_bucket(CLOUD_BUCKET_NAME, project=PROJECT_ID)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile() as temp:\n",
    "        df.to_csv(temp.name, index=False,sep='\\t')\n",
    "        with open(temp.name, 'rb') as source_file:\n",
    "            # upload to google cloud\n",
    "            storage_client = storage.Client()\n",
    "            bucket = storage_client.bucket(CLOUD_BUCKET_NAME)\n",
    "            blob = bucket.blob(filepath)\n",
    "\n",
    "            blob.upload_from_file(temp.name,content_type='text/tab-separated-values')\n",
    "\n",
    "    print(\"File data_frame uploaded to {}\".format(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conat the Columns into Text blob and upload tsv to cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get data from big query\n",
    "print('Executing big query')\n",
    "df = pd.read_gbq(QUERY2, project_id=PROJECT_ID, dialect='standard', progress_bar_type='tqdm')\n",
    "print('Finised big query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Uravel claims - for some reason it was in a dictionary\n",
    "df.claims = df.claims.apply(lambda x: x['claims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange data schema\n",
    "print('Rearrange cols')\n",
    "df = df[COLUMNS]\n",
    "print('Finished Rearrange cols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adding token delimiters')\n",
    "\n",
    "df = addFieldTokens(df,START_TOKENS,END_TOKENS,VAR_COLUMNS)\n",
    "print('Finished adding delimiters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the tokens to the filed\n",
    "print('Conc colu,ns')\n",
    "df[\"text\"] = \"\"\n",
    "i=0\n",
    "for col in VAR_COLUMNS:\n",
    "    df[\"text\"]+=\" \"+df[col]\n",
    "    if col!= \"patent_id\" and col !=\"publication_date\":\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "    i+=1\n",
    "    print(\"{}/{} done\".format(i,len(VAR_COLUMNS)))\n",
    "print('Finished adding delimiters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the coulms to one text blob\n",
    "print('Creating text blobs')\n",
    "concatColumns(df)\n",
    "print('Finished text blobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload to big cloud storage\n",
    "print('Uploading to cloud storages')\n",
    "#upload_df_toGoogle(df)\n",
    "\n",
    "df.to_csv('gs://patents-research/patent_research/data_frwdcorrect.tsv', sep='\\t',index=False)\n",
    "\n",
    "#df.read_csv('gs://patents-research/patent_research/data_frwdcorrect.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "df.fwrdCitations_5.describe(percentiles=[.25, .5, .75, .95,.99] )   \n",
    "\n",
    "\n",
    "print('Finished to cloud storages')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patent-modeling",
   "language": "python",
   "name": "patent-modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
